{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arzoozehra/CIND820/blob/main/unsupervised_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "-bkY_pYm8WwM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wr2dHIs7WLWJ",
        "outputId": "4d30e9b1-074e-42a0-ccd2-10264858ece8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 39.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "!pip install contractions\n",
        "import contractions\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "#!pip install pyspellchecker\n",
        "#from spellchecker import SpellChecker\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense, Dropout\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.python.keras.optimizer_v2.adam import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data**"
      ],
      "metadata": {
        "id": "GfYAFFPs8gNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/arzoozehra/CIND820/main/data/train.csv\"\n",
        "train = pd.read_csv(url)\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/arzoozehra/CIND820/main/data/test.csv\")\n",
        "\n",
        "train.drop([\"textID\", \"selected_text\"], axis=1, inplace=True)\n",
        "test.drop([\"textID\"], axis=1, inplace=True)\n",
        "\n",
        "# Remove row with missing values\n",
        "train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "WzPmmeuGrev1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean data**"
      ],
      "metadata": {
        "id": "QbW4UiEpq9kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(data):\n",
        "  \n",
        "  # Convert text to lowercase\n",
        "  data[\"text\"] = data[\"text\"].str.lower()\n",
        "\n",
        "  # Expand contractions e.g \"gonna\" to \"going to\" and \"i've\" to \"i have\"\n",
        "  data[\"text\"].replace( {r\"`\": \"'\"}, inplace= True, regex = True)\n",
        "  data[\"text\"] = data[\"text\"].apply(contractions.fix)\n",
        "\n",
        "  # Remove @, Unicode characters, punctuation, emojis, URLs, retweets, words with digits, and 1 or 2 letter words\n",
        "  data[\"text\"].replace( {r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?|\\w*\\d\\w*|\\b\\w{1,2}\\b\": \" \"}, inplace= True, regex = True)\n",
        "\n",
        "  # Remove extra whitespaces\n",
        "  data[\"text\"].replace( {r\" +\": \" \"}, inplace= True, regex = True)\n",
        "  data[\"text\"] = data[\"text\"].str.strip()\n",
        "\n",
        "  # Correct spellings\n",
        "  #spell = SpellChecker()\n",
        "\n",
        "  #def correct_spellings(text):\n",
        "  #    corrected_text = []\n",
        "  #    misspelled_words = {}\n",
        "  #    words = text.split()\n",
        "  #    for w in spell.unknown(words):\n",
        "  #        corr = spell.correction(w)\n",
        "  #        if corr:\n",
        "  #            misspelled_words[w] = spell.correction(w) or w\n",
        "  #    corrected_text = [misspelled_words.get(w, w) for w in words]\n",
        "  #    return \" \".join(corrected_text)\n",
        "\n",
        "  #data[\"text\"] = data[\"text\"].apply(lambda x : correct_spellings(x))\n",
        "\n",
        "  # Remove stopwords\n",
        "  stop = stopwords.words(\"english\")\n",
        "  data[\"text\"] = data[\"text\"].apply(lambda text: \" \".join([word for word in text.split() if word not in (stop)]))\n",
        "\n",
        "  # Stemming\n",
        "  stemmer = PorterStemmer()\n",
        "  data[\"text\"] = data[\"text\"].apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split()]))\n",
        "\n",
        "  # Lemmatizing\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  data[\"text\"] = data[\"text\"].apply(lambda text: \" \".join([lemmatizer.lemmatize(word) for word in text.split()]))\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "5tDnIMd-q89D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean trraining data\n",
        "train = clean_data(train)\n",
        "\n",
        "#Clean testing data\n",
        "test = clean_data(test)"
      ],
      "metadata": {
        "id": "lil3NvKYD-3j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(labels):\n",
        "    \"\"\"Gets the total number of classes.\n",
        "    # Arguments\n",
        "        labels: list, label values.\n",
        "            There should be at lease one sample for values in the\n",
        "            range (0, num_classes -1)\n",
        "    # Returns\n",
        "        int, total number of classes.\n",
        "    # Raises\n",
        "        ValueError: if any label value in the range(0, num_classes - 1)\n",
        "            is missing or if number of classes is <= 1.\n",
        "    \"\"\"\n",
        "    num_classes = max(labels) + 1\n",
        "    missing_classes = [i for i in range(num_classes) if i not in labels]\n",
        "    if len(missing_classes):\n",
        "        raise ValueError('Missing samples with label value(s) '\n",
        "                         '{missing_classes}. Please make sure you have '\n",
        "                         'at least one sample for every label value '\n",
        "                         'in the range(0, {max_class})'.format(\n",
        "                            missing_classes=missing_classes,\n",
        "                            max_class=num_classes - 1))\n",
        "\n",
        "    if num_classes <= 1:\n",
        "        raise ValueError('Invalid number of labels: {num_classes}.'\n",
        "                         'Please make sure there are at least two classes '\n",
        "                         'of samples'.format(num_classes=num_classes))\n",
        "    return num_classes\n"
      ],
      "metadata": {
        "id": "15cg2iGGlFZd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Feature Selection**"
      ],
      "metadata": {
        "id": "SRySCY_E8Kke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization parameters\n",
        "\n",
        "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
        "  \"\"\"Vectorizes texts as ngram vectors.\n",
        "  1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.\n",
        "  # Arguments\n",
        "      train_texts: list, training text strings.\n",
        "      train_labels: np.ndarray, training labels.\n",
        "      val_texts: list, validation text strings.\n",
        "  # Returns\n",
        "      x_train, x_val: vectorized training and validation texts\n",
        "  \"\"\"\n",
        "  # Range (inclusive) of n-gram sizes for tokenizing text.\n",
        "  # Use 1-grams + 2-grams.\n",
        "  NGRAM_RANGE = (1, 2)\n",
        "\n",
        "  # Whether text should be split into word or character n-grams.\n",
        "  # Split text into word tokens.\n",
        "  TOKEN_MODE = 'word'\n",
        "\n",
        "  # Minimum document/corpus frequency below which a token will be discarded.\n",
        "  MIN_DOCUMENT_FREQUENCY = 5\n",
        "\n",
        "  # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
        "  kwargs = {\n",
        "          \"ngram_range\": NGRAM_RANGE,\n",
        "          \"analyzer\": TOKEN_MODE,  \n",
        "          \"min_df\": MIN_DOCUMENT_FREQUENCY,\n",
        "          \"max_df\" : 0.8,\n",
        "          \"sublinear_tf\": \"True\"\n",
        "  }\n",
        "  vectorizer = TfidfVectorizer(**kwargs)\n",
        "\n",
        "  # Learn vocabulary from training texts and vectorize training texts.\n",
        "  x_train = vectorizer.fit_transform(train_texts).toarray()\n",
        "\n",
        "  # Vectorize validation texts.\n",
        "  x_val = vectorizer.transform(val_texts).toarray()\n",
        "\n",
        "  return x_train, x_val"
      ],
      "metadata": {
        "id": "eVC51r3aO6-6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unsupervised modelling using TensorFlow**"
      ],
      "metadata": {
        "id": "fp5HLVdNboZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_model(layers, units, dropout_rate, input_shape, op_units=3, op_activation='softmax'):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        op_units: int, number of output classes.\n",
        "        op_activation: softmax for multiclass\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance.\n",
        "    \"\"\"\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
        "\n",
        "    for _ in range(layers-1):\n",
        "        model.add(Dense(units=units, activation='relu'))\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(units=op_units, activation=op_activation))\n",
        "    return model"
      ],
      "metadata": {
        "id": "lyYc_8N3bkb7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train model**"
      ],
      "metadata": {
        "id": "0ujbGFwieJlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ngram_model(train, test,\n",
        "                      learning_rate=1e-3,\n",
        "                      epochs=1000,\n",
        "                      batch_size=128,\n",
        "                      layers=2,\n",
        "                      units=64,\n",
        "                      dropout_rate=0.2):\n",
        "    \"\"\"Trains n-gram model on the given dataset.\n",
        "    # Arguments\n",
        "        train, test: tuples of training and test texts and labels.\n",
        "        learning_rate: float, learning rate for training model.\n",
        "        epochs: int, number of epochs.\n",
        "        batch_size: int, number of samples per batch.\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of Dense layers in the model.\n",
        "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
        "    # Raises\n",
        "        ValueError: If validation data has label values which were not seen\n",
        "            in the training data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the data\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(train[\"text\"], train[\"sentiment\"], test_size=0.2, random_state=42)\n",
        "\n",
        "    # Encode train and test labels\n",
        "    le = LabelEncoder()\n",
        "    train_labels = le.fit_transform(train_labels)\n",
        "    val_labels = le.fit_transform(val_labels)\n",
        "\n",
        "    # Verify that validation labels are in the same range as training labels.\n",
        "    num_classes = get_num_classes(train_labels)\n",
        "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
        "    if len(unexpected_labels):\n",
        "        raise ValueError('Unexpected label values found in the validation set:'\n",
        "                          ' {unexpected_labels}. Please make sure that the '\n",
        "                          'labels in the validation set are in the same range '\n",
        "                          'as training labels.'.format(\n",
        "                              unexpected_labels=unexpected_labels))\n",
        "\n",
        "\n",
        "    # Vectorize texts.\n",
        "    x_train, x_val = ngram_vectorize(train_texts, train_labels, val_texts)\n",
        "\n",
        "    # Create model instance.\n",
        "    model = mlp_model(layers=layers,\n",
        "                      units=units,\n",
        "                      dropout_rate=dropout_rate,\n",
        "                      input_shape=x_train.shape[1:])\n",
        "\n",
        "    # Compile model with learning parameters.\n",
        "    loss = 'sparse_categorical_crossentropy'\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "    # Create callback for early stopping on validation loss. If the loss does\n",
        "    # not decrease in two consecutive tries, stop training.\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
        "\n",
        "    # Train and validate model.\n",
        "    history = model.fit(x_train, train_labels,\n",
        "                        epochs = epochs,\n",
        "                        callbacks = callbacks,\n",
        "                        validation_data = (x_val, val_labels),\n",
        "                        verbose = 2,  # Logs once per epoch.\n",
        "                        batch_size = batch_size\n",
        "    )\n",
        "\n",
        "    # Print results.\n",
        "    history = history.history\n",
        "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
        "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
        "\n",
        "    # Save model.\n",
        "    #model.save('tfNN_model.h5')\n",
        "    return(history['val_acc'][-1], history['val_loss'][-1], model)"
      ],
      "metadata": {
        "id": "C0ySmmzIdhdS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc, loss, model = train_ngram_model(train, test)"
      ],
      "metadata": {
        "id": "atI-0q9x1AWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMYkzjLVZzPU",
        "outputId": "52b19935-d4a8-4a3e-d126-d0f57204bd2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout_4 (Dropout)          (None, 4636)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                296768    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 296,963\n",
            "Trainable params: 296,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.get_config()"
      ],
      "metadata": {
        "id": "NSZ6_M9gE74P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_ngram_model(train, test):\n",
        "    \"\"\"Tunes n-gram model on the given dataset.\n",
        "    # Arguments\n",
        "        data: tuples of training and test texts and labels.\n",
        "    \"\"\"\n",
        "    # Select parameter values to try.\n",
        "    num_layers = [1, 2, 3]\n",
        "    num_units = [8, 16, 32, 64, 128]\n",
        "\n",
        "    entries = []\n",
        "\n",
        "    # Save parameter combination and results.\n",
        "    params = {\n",
        "        'layers': [],\n",
        "        'units': [],\n",
        "        'accuracy': [],\n",
        "    }\n",
        "\n",
        "    # Iterate over all parameter combinations.\n",
        "    for layers in num_layers:\n",
        "        for units in num_units:\n",
        "                params['layers'].append(layers)\n",
        "                params['units'].append(units)\n",
        "\n",
        "                accuracy, _, _= train_ngram_model(train=train,\n",
        "                                                  test=test,\n",
        "                                                  layers=layers,\n",
        "                                                  units=units)\n",
        "                entries.append(('Accuracy: {accuracy}, Parameters: (layers={layers}, '\n",
        "                       'units={units})').format(accuracy=accuracy,\n",
        "                                                layers=layers,\n",
        "                                                units=units))\n",
        "                params['accuracy'].append(accuracy)\n",
        "    _plot_parameters(params)\n",
        "    return entries"
      ],
      "metadata": {
        "id": "iex-7P_Dsc74"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _plot_parameters(params):\n",
        "    \"\"\"Creates a 3D surface plot of given parameters.\n",
        "    # Arguments\n",
        "        params: dict, contains layers, units and accuracy value combinations.\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.gca(projection='3d')\n",
        "    ax.plot_trisurf(params['layers'],\n",
        "                    params['units'],\n",
        "                    params['accuracy'],\n",
        "                    cmap=\"Blues\",\n",
        "                    antialiased=False)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "A3C3RSYeszGv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = tune_ngram_model(train, test)"
      ],
      "metadata": {
        "id": "lGKVF17KuyRs",
        "outputId": "b6928957-3e09-4303-937b-66b731a4f0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0750 - acc: 0.4356 - val_loss: 1.0538 - val_acc: 0.4571\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 1.0320 - acc: 0.4804 - val_loss: 1.0219 - val_acc: 0.4995\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.9973 - acc: 0.5338 - val_loss: 0.9947 - val_acc: 0.5384\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.9678 - acc: 0.5733 - val_loss: 0.9714 - val_acc: 0.5679\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.9415 - acc: 0.6030 - val_loss: 0.9510 - val_acc: 0.5888\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.9187 - acc: 0.6278 - val_loss: 0.9330 - val_acc: 0.6033\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.8982 - acc: 0.6462 - val_loss: 0.9170 - val_acc: 0.6164\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.8771 - acc: 0.6550 - val_loss: 0.9029 - val_acc: 0.6274\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.8621 - acc: 0.6646 - val_loss: 0.8902 - val_acc: 0.6321\n",
            "Epoch 10/1000\n",
            "172/172 - 2s - loss: 0.8488 - acc: 0.6705 - val_loss: 0.8791 - val_acc: 0.6388\n",
            "Epoch 11/1000\n",
            "172/172 - 2s - loss: 0.8350 - acc: 0.6749 - val_loss: 0.8688 - val_acc: 0.6432\n",
            "Epoch 12/1000\n",
            "172/172 - 2s - loss: 0.8213 - acc: 0.6842 - val_loss: 0.8598 - val_acc: 0.6443\n",
            "Epoch 13/1000\n",
            "172/172 - 4s - loss: 0.8109 - acc: 0.6840 - val_loss: 0.8515 - val_acc: 0.6488\n",
            "Epoch 14/1000\n",
            "172/172 - 2s - loss: 0.8010 - acc: 0.6937 - val_loss: 0.8439 - val_acc: 0.6501\n",
            "Epoch 15/1000\n",
            "172/172 - 2s - loss: 0.7896 - acc: 0.6941 - val_loss: 0.8371 - val_acc: 0.6514\n",
            "Epoch 16/1000\n",
            "172/172 - 2s - loss: 0.7817 - acc: 0.6944 - val_loss: 0.8308 - val_acc: 0.6537\n",
            "Epoch 17/1000\n",
            "172/172 - 2s - loss: 0.7721 - acc: 0.6997 - val_loss: 0.8250 - val_acc: 0.6559\n",
            "Epoch 18/1000\n",
            "172/172 - 2s - loss: 0.7655 - acc: 0.7005 - val_loss: 0.8197 - val_acc: 0.6572\n",
            "Epoch 19/1000\n",
            "172/172 - 2s - loss: 0.7569 - acc: 0.7056 - val_loss: 0.8149 - val_acc: 0.6579\n",
            "Epoch 20/1000\n",
            "172/172 - 2s - loss: 0.7514 - acc: 0.7067 - val_loss: 0.8105 - val_acc: 0.6590\n",
            "Epoch 21/1000\n",
            "172/172 - 2s - loss: 0.7455 - acc: 0.7087 - val_loss: 0.8065 - val_acc: 0.6619\n",
            "Epoch 22/1000\n",
            "172/172 - 2s - loss: 0.7395 - acc: 0.7106 - val_loss: 0.8028 - val_acc: 0.6614\n",
            "Epoch 23/1000\n",
            "172/172 - 2s - loss: 0.7328 - acc: 0.7143 - val_loss: 0.7993 - val_acc: 0.6630\n",
            "Epoch 24/1000\n",
            "172/172 - 2s - loss: 0.7269 - acc: 0.7155 - val_loss: 0.7962 - val_acc: 0.6650\n",
            "Epoch 25/1000\n",
            "172/172 - 2s - loss: 0.7204 - acc: 0.7182 - val_loss: 0.7931 - val_acc: 0.6627\n",
            "Epoch 26/1000\n",
            "172/172 - 2s - loss: 0.7157 - acc: 0.7174 - val_loss: 0.7904 - val_acc: 0.6647\n",
            "Epoch 27/1000\n",
            "172/172 - 2s - loss: 0.7103 - acc: 0.7231 - val_loss: 0.7879 - val_acc: 0.6672\n",
            "Epoch 28/1000\n",
            "172/172 - 2s - loss: 0.7091 - acc: 0.7208 - val_loss: 0.7856 - val_acc: 0.6668\n",
            "Epoch 29/1000\n",
            "172/172 - 2s - loss: 0.7052 - acc: 0.7214 - val_loss: 0.7838 - val_acc: 0.6681\n",
            "Epoch 30/1000\n",
            "172/172 - 2s - loss: 0.6997 - acc: 0.7260 - val_loss: 0.7817 - val_acc: 0.6672\n",
            "Epoch 31/1000\n",
            "172/172 - 2s - loss: 0.6975 - acc: 0.7251 - val_loss: 0.7800 - val_acc: 0.6656\n",
            "Epoch 32/1000\n",
            "172/172 - 2s - loss: 0.6909 - acc: 0.7293 - val_loss: 0.7785 - val_acc: 0.6672\n",
            "Epoch 33/1000\n",
            "172/172 - 2s - loss: 0.6907 - acc: 0.7238 - val_loss: 0.7771 - val_acc: 0.6690\n",
            "Epoch 34/1000\n",
            "172/172 - 2s - loss: 0.6907 - acc: 0.7271 - val_loss: 0.7757 - val_acc: 0.6689\n",
            "Epoch 35/1000\n",
            "172/172 - 2s - loss: 0.6855 - acc: 0.7284 - val_loss: 0.7745 - val_acc: 0.6712\n",
            "Epoch 36/1000\n",
            "172/172 - 2s - loss: 0.6844 - acc: 0.7296 - val_loss: 0.7734 - val_acc: 0.6705\n",
            "Epoch 37/1000\n",
            "172/172 - 2s - loss: 0.6825 - acc: 0.7286 - val_loss: 0.7723 - val_acc: 0.6712\n",
            "Epoch 38/1000\n",
            "172/172 - 2s - loss: 0.6774 - acc: 0.7315 - val_loss: 0.7713 - val_acc: 0.6699\n",
            "Epoch 39/1000\n",
            "172/172 - 2s - loss: 0.6735 - acc: 0.7338 - val_loss: 0.7704 - val_acc: 0.6696\n",
            "Epoch 40/1000\n",
            "172/172 - 2s - loss: 0.6715 - acc: 0.7315 - val_loss: 0.7694 - val_acc: 0.6714\n",
            "Epoch 41/1000\n",
            "172/172 - 2s - loss: 0.6733 - acc: 0.7311 - val_loss: 0.7687 - val_acc: 0.6729\n",
            "Epoch 42/1000\n",
            "172/172 - 2s - loss: 0.6650 - acc: 0.7367 - val_loss: 0.7681 - val_acc: 0.6732\n",
            "Epoch 43/1000\n",
            "172/172 - 2s - loss: 0.6613 - acc: 0.7383 - val_loss: 0.7676 - val_acc: 0.6723\n",
            "Epoch 44/1000\n",
            "172/172 - 2s - loss: 0.6624 - acc: 0.7376 - val_loss: 0.7671 - val_acc: 0.6721\n",
            "Epoch 45/1000\n",
            "172/172 - 2s - loss: 0.6631 - acc: 0.7355 - val_loss: 0.7669 - val_acc: 0.6707\n",
            "Epoch 46/1000\n",
            "172/172 - 2s - loss: 0.6558 - acc: 0.7405 - val_loss: 0.7663 - val_acc: 0.6721\n",
            "Epoch 47/1000\n",
            "172/172 - 2s - loss: 0.6556 - acc: 0.7404 - val_loss: 0.7660 - val_acc: 0.6712\n",
            "Epoch 48/1000\n",
            "172/172 - 2s - loss: 0.6530 - acc: 0.7399 - val_loss: 0.7657 - val_acc: 0.6712\n",
            "Epoch 49/1000\n",
            "172/172 - 2s - loss: 0.6512 - acc: 0.7424 - val_loss: 0.7655 - val_acc: 0.6703\n",
            "Epoch 50/1000\n",
            "172/172 - 2s - loss: 0.6520 - acc: 0.7420 - val_loss: 0.7652 - val_acc: 0.6701\n",
            "Epoch 51/1000\n",
            "172/172 - 2s - loss: 0.6510 - acc: 0.7426 - val_loss: 0.7652 - val_acc: 0.6707\n",
            "Epoch 52/1000\n",
            "172/172 - 2s - loss: 0.6510 - acc: 0.7409 - val_loss: 0.7652 - val_acc: 0.6699\n",
            "Epoch 53/1000\n",
            "172/172 - 2s - loss: 0.6427 - acc: 0.7470 - val_loss: 0.7651 - val_acc: 0.6703\n",
            "Epoch 54/1000\n",
            "172/172 - 2s - loss: 0.6471 - acc: 0.7416 - val_loss: 0.7650 - val_acc: 0.6698\n",
            "Epoch 55/1000\n",
            "172/172 - 2s - loss: 0.6448 - acc: 0.7441 - val_loss: 0.7650 - val_acc: 0.6705\n",
            "Epoch 56/1000\n",
            "172/172 - 2s - loss: 0.6427 - acc: 0.7450 - val_loss: 0.7650 - val_acc: 0.6703\n",
            "Epoch 57/1000\n",
            "172/172 - 2s - loss: 0.6381 - acc: 0.7454 - val_loss: 0.7650 - val_acc: 0.6698\n",
            "Epoch 58/1000\n",
            "172/172 - 2s - loss: 0.6387 - acc: 0.7445 - val_loss: 0.7652 - val_acc: 0.6692\n",
            "Validation accuracy: 0.6692139506340027, loss: 0.7652183771133423\n",
            "Accuracy: 0.6692139506340027, Parameters: (layers=1, units=8)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0737 - acc: 0.4508 - val_loss: 1.0522 - val_acc: 0.4625\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 1.0309 - acc: 0.4881 - val_loss: 1.0202 - val_acc: 0.4958\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.9955 - acc: 0.5346 - val_loss: 0.9931 - val_acc: 0.5448\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.9670 - acc: 0.5767 - val_loss: 0.9700 - val_acc: 0.5710\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.9408 - acc: 0.6037 - val_loss: 0.9497 - val_acc: 0.5892\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.9183 - acc: 0.6260 - val_loss: 0.9318 - val_acc: 0.6072\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.8965 - acc: 0.6417 - val_loss: 0.9159 - val_acc: 0.6197\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.8788 - acc: 0.6553 - val_loss: 0.9020 - val_acc: 0.6268\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.8623 - acc: 0.6629 - val_loss: 0.8894 - val_acc: 0.6326\n",
            "Epoch 10/1000\n",
            "172/172 - 2s - loss: 0.8470 - acc: 0.6734 - val_loss: 0.8780 - val_acc: 0.6385\n",
            "Epoch 11/1000\n",
            "172/172 - 2s - loss: 0.8342 - acc: 0.6733 - val_loss: 0.8678 - val_acc: 0.6452\n",
            "Epoch 12/1000\n",
            "172/172 - 3s - loss: 0.8196 - acc: 0.6836 - val_loss: 0.8586 - val_acc: 0.6483\n",
            "Epoch 13/1000\n",
            "172/172 - 2s - loss: 0.8095 - acc: 0.6857 - val_loss: 0.8502 - val_acc: 0.6519\n",
            "Epoch 14/1000\n",
            "172/172 - 2s - loss: 0.8001 - acc: 0.6881 - val_loss: 0.8429 - val_acc: 0.6541\n",
            "Epoch 15/1000\n",
            "172/172 - 2s - loss: 0.7880 - acc: 0.6964 - val_loss: 0.8361 - val_acc: 0.6541\n",
            "Epoch 16/1000\n",
            "172/172 - 2s - loss: 0.7800 - acc: 0.6948 - val_loss: 0.8299 - val_acc: 0.6539\n",
            "Epoch 17/1000\n",
            "172/172 - 2s - loss: 0.7716 - acc: 0.7012 - val_loss: 0.8242 - val_acc: 0.6563\n",
            "Epoch 18/1000\n",
            "172/172 - 2s - loss: 0.7652 - acc: 0.7031 - val_loss: 0.8189 - val_acc: 0.6576\n",
            "Epoch 19/1000\n",
            "172/172 - 2s - loss: 0.7556 - acc: 0.7058 - val_loss: 0.8140 - val_acc: 0.6576\n",
            "Epoch 20/1000\n",
            "172/172 - 2s - loss: 0.7482 - acc: 0.7065 - val_loss: 0.8097 - val_acc: 0.6596\n",
            "Epoch 21/1000\n",
            "172/172 - 2s - loss: 0.7449 - acc: 0.7085 - val_loss: 0.8056 - val_acc: 0.6603\n",
            "Epoch 22/1000\n",
            "172/172 - 2s - loss: 0.7371 - acc: 0.7116 - val_loss: 0.8019 - val_acc: 0.6627\n",
            "Epoch 23/1000\n",
            "172/172 - 2s - loss: 0.7339 - acc: 0.7126 - val_loss: 0.7988 - val_acc: 0.6634\n",
            "Epoch 24/1000\n",
            "172/172 - 2s - loss: 0.7281 - acc: 0.7133 - val_loss: 0.7957 - val_acc: 0.6628\n",
            "Epoch 25/1000\n",
            "172/172 - 2s - loss: 0.7237 - acc: 0.7150 - val_loss: 0.7928 - val_acc: 0.6648\n",
            "Epoch 26/1000\n",
            "172/172 - 2s - loss: 0.7173 - acc: 0.7193 - val_loss: 0.7902 - val_acc: 0.6665\n",
            "Epoch 27/1000\n",
            "172/172 - 2s - loss: 0.7130 - acc: 0.7203 - val_loss: 0.7875 - val_acc: 0.6672\n",
            "Epoch 28/1000\n",
            "172/172 - 2s - loss: 0.7080 - acc: 0.7212 - val_loss: 0.7853 - val_acc: 0.6667\n",
            "Epoch 29/1000\n",
            "172/172 - 2s - loss: 0.7049 - acc: 0.7211 - val_loss: 0.7833 - val_acc: 0.6670\n",
            "Epoch 30/1000\n",
            "172/172 - 2s - loss: 0.7034 - acc: 0.7224 - val_loss: 0.7813 - val_acc: 0.6681\n",
            "Epoch 31/1000\n",
            "172/172 - 2s - loss: 0.7018 - acc: 0.7228 - val_loss: 0.7796 - val_acc: 0.6672\n",
            "Epoch 32/1000\n",
            "172/172 - 2s - loss: 0.6936 - acc: 0.7276 - val_loss: 0.7779 - val_acc: 0.6687\n",
            "Epoch 33/1000\n",
            "172/172 - 2s - loss: 0.6928 - acc: 0.7274 - val_loss: 0.7764 - val_acc: 0.6678\n",
            "Epoch 34/1000\n",
            "172/172 - 2s - loss: 0.6890 - acc: 0.7268 - val_loss: 0.7752 - val_acc: 0.6678\n",
            "Epoch 35/1000\n",
            "172/172 - 2s - loss: 0.6870 - acc: 0.7282 - val_loss: 0.7739 - val_acc: 0.6725\n",
            "Epoch 36/1000\n",
            "172/172 - 2s - loss: 0.6836 - acc: 0.7295 - val_loss: 0.7729 - val_acc: 0.6707\n",
            "Epoch 37/1000\n",
            "172/172 - 2s - loss: 0.6804 - acc: 0.7295 - val_loss: 0.7718 - val_acc: 0.6709\n",
            "Epoch 38/1000\n",
            "172/172 - 2s - loss: 0.6751 - acc: 0.7312 - val_loss: 0.7707 - val_acc: 0.6718\n",
            "Epoch 39/1000\n",
            "172/172 - 2s - loss: 0.6734 - acc: 0.7338 - val_loss: 0.7698 - val_acc: 0.6719\n",
            "Epoch 40/1000\n",
            "172/172 - 2s - loss: 0.6707 - acc: 0.7334 - val_loss: 0.7691 - val_acc: 0.6723\n",
            "Epoch 41/1000\n",
            "172/172 - 2s - loss: 0.6697 - acc: 0.7325 - val_loss: 0.7686 - val_acc: 0.6730\n",
            "Epoch 42/1000\n",
            "172/172 - 2s - loss: 0.6648 - acc: 0.7334 - val_loss: 0.7679 - val_acc: 0.6716\n",
            "Epoch 43/1000\n",
            "172/172 - 2s - loss: 0.6651 - acc: 0.7338 - val_loss: 0.7672 - val_acc: 0.6709\n",
            "Epoch 44/1000\n",
            "172/172 - 2s - loss: 0.6630 - acc: 0.7362 - val_loss: 0.7666 - val_acc: 0.6707\n",
            "Epoch 45/1000\n",
            "172/172 - 2s - loss: 0.6615 - acc: 0.7350 - val_loss: 0.7663 - val_acc: 0.6714\n",
            "Epoch 46/1000\n",
            "172/172 - 2s - loss: 0.6618 - acc: 0.7342 - val_loss: 0.7658 - val_acc: 0.6710\n",
            "Epoch 47/1000\n",
            "172/172 - 2s - loss: 0.6570 - acc: 0.7351 - val_loss: 0.7656 - val_acc: 0.6709\n",
            "Epoch 48/1000\n",
            "172/172 - 2s - loss: 0.6576 - acc: 0.7382 - val_loss: 0.7652 - val_acc: 0.6721\n",
            "Epoch 49/1000\n",
            "172/172 - 2s - loss: 0.6533 - acc: 0.7413 - val_loss: 0.7650 - val_acc: 0.6725\n",
            "Epoch 50/1000\n",
            "172/172 - 2s - loss: 0.6513 - acc: 0.7410 - val_loss: 0.7648 - val_acc: 0.6732\n",
            "Epoch 51/1000\n",
            "172/172 - 2s - loss: 0.6468 - acc: 0.7414 - val_loss: 0.7646 - val_acc: 0.6716\n",
            "Epoch 52/1000\n",
            "172/172 - 2s - loss: 0.6468 - acc: 0.7415 - val_loss: 0.7647 - val_acc: 0.6721\n",
            "Epoch 53/1000\n",
            "172/172 - 2s - loss: 0.6504 - acc: 0.7394 - val_loss: 0.7645 - val_acc: 0.6716\n",
            "Epoch 54/1000\n",
            "172/172 - 2s - loss: 0.6476 - acc: 0.7396 - val_loss: 0.7647 - val_acc: 0.6712\n",
            "Epoch 55/1000\n",
            "172/172 - 2s - loss: 0.6411 - acc: 0.7461 - val_loss: 0.7645 - val_acc: 0.6703\n",
            "Validation accuracy: 0.6703056693077087, loss: 0.7645335793495178\n",
            "Accuracy: 0.6703056693077087, Parameters: (layers=1, units=16)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0744 - acc: 0.4456 - val_loss: 1.0529 - val_acc: 0.4583\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 1.0313 - acc: 0.4862 - val_loss: 1.0208 - val_acc: 0.4960\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.9971 - acc: 0.5332 - val_loss: 0.9940 - val_acc: 0.5406\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.9672 - acc: 0.5732 - val_loss: 0.9707 - val_acc: 0.5673\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.9408 - acc: 0.6032 - val_loss: 0.9503 - val_acc: 0.5915\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.9168 - acc: 0.6320 - val_loss: 0.9321 - val_acc: 0.6039\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.8971 - acc: 0.6390 - val_loss: 0.9162 - val_acc: 0.6168\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.8782 - acc: 0.6562 - val_loss: 0.9020 - val_acc: 0.6263\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.8623 - acc: 0.6639 - val_loss: 0.8895 - val_acc: 0.6345\n",
            "Epoch 10/1000\n",
            "172/172 - 2s - loss: 0.8458 - acc: 0.6691 - val_loss: 0.8782 - val_acc: 0.6383\n",
            "Epoch 11/1000\n",
            "172/172 - 2s - loss: 0.8345 - acc: 0.6764 - val_loss: 0.8681 - val_acc: 0.6421\n",
            "Epoch 12/1000\n",
            "172/172 - 2s - loss: 0.8211 - acc: 0.6813 - val_loss: 0.8588 - val_acc: 0.6457\n",
            "Epoch 13/1000\n",
            "172/172 - 2s - loss: 0.8092 - acc: 0.6852 - val_loss: 0.8505 - val_acc: 0.6496\n",
            "Epoch 14/1000\n",
            "172/172 - 2s - loss: 0.7999 - acc: 0.6925 - val_loss: 0.8431 - val_acc: 0.6508\n",
            "Epoch 15/1000\n",
            "172/172 - 2s - loss: 0.7891 - acc: 0.6930 - val_loss: 0.8363 - val_acc: 0.6528\n",
            "Epoch 16/1000\n",
            "172/172 - 2s - loss: 0.7808 - acc: 0.6949 - val_loss: 0.8299 - val_acc: 0.6559\n",
            "Epoch 17/1000\n",
            "172/172 - 2s - loss: 0.7737 - acc: 0.6976 - val_loss: 0.8243 - val_acc: 0.6567\n",
            "Epoch 18/1000\n",
            "172/172 - 2s - loss: 0.7640 - acc: 0.7032 - val_loss: 0.8192 - val_acc: 0.6568\n",
            "Epoch 19/1000\n",
            "172/172 - 2s - loss: 0.7568 - acc: 0.7081 - val_loss: 0.8143 - val_acc: 0.6583\n",
            "Epoch 20/1000\n",
            "172/172 - 2s - loss: 0.7519 - acc: 0.7046 - val_loss: 0.8100 - val_acc: 0.6592\n",
            "Epoch 21/1000\n",
            "172/172 - 2s - loss: 0.7476 - acc: 0.7082 - val_loss: 0.8060 - val_acc: 0.6596\n",
            "Epoch 22/1000\n",
            "172/172 - 2s - loss: 0.7383 - acc: 0.7114 - val_loss: 0.8023 - val_acc: 0.6608\n",
            "Epoch 23/1000\n",
            "172/172 - 2s - loss: 0.7319 - acc: 0.7141 - val_loss: 0.7989 - val_acc: 0.6623\n",
            "Epoch 24/1000\n",
            "172/172 - 2s - loss: 0.7297 - acc: 0.7126 - val_loss: 0.7958 - val_acc: 0.6650\n",
            "Epoch 25/1000\n",
            "172/172 - 2s - loss: 0.7232 - acc: 0.7170 - val_loss: 0.7929 - val_acc: 0.6658\n",
            "Epoch 26/1000\n",
            "172/172 - 2s - loss: 0.7195 - acc: 0.7171 - val_loss: 0.7902 - val_acc: 0.6674\n",
            "Epoch 27/1000\n",
            "172/172 - 2s - loss: 0.7111 - acc: 0.7234 - val_loss: 0.7876 - val_acc: 0.6689\n",
            "Epoch 28/1000\n",
            "172/172 - 2s - loss: 0.7115 - acc: 0.7176 - val_loss: 0.7853 - val_acc: 0.6678\n",
            "Epoch 29/1000\n",
            "172/172 - 4s - loss: 0.7051 - acc: 0.7198 - val_loss: 0.7832 - val_acc: 0.6699\n",
            "Epoch 30/1000\n",
            "172/172 - 2s - loss: 0.7010 - acc: 0.7231 - val_loss: 0.7812 - val_acc: 0.6690\n",
            "Epoch 31/1000\n",
            "172/172 - 2s - loss: 0.6992 - acc: 0.7243 - val_loss: 0.7795 - val_acc: 0.6683\n",
            "Epoch 32/1000\n",
            "172/172 - 2s - loss: 0.6939 - acc: 0.7248 - val_loss: 0.7779 - val_acc: 0.6701\n",
            "Epoch 33/1000\n",
            "172/172 - 2s - loss: 0.6878 - acc: 0.7286 - val_loss: 0.7765 - val_acc: 0.6690\n",
            "Epoch 34/1000\n",
            "172/172 - 2s - loss: 0.6854 - acc: 0.7288 - val_loss: 0.7752 - val_acc: 0.6694\n",
            "Epoch 35/1000\n",
            "172/172 - 2s - loss: 0.6859 - acc: 0.7282 - val_loss: 0.7740 - val_acc: 0.6705\n",
            "Epoch 36/1000\n",
            "172/172 - 2s - loss: 0.6813 - acc: 0.7303 - val_loss: 0.7729 - val_acc: 0.6714\n",
            "Epoch 37/1000\n",
            "172/172 - 2s - loss: 0.6789 - acc: 0.7299 - val_loss: 0.7719 - val_acc: 0.6709\n",
            "Epoch 38/1000\n",
            "172/172 - 2s - loss: 0.6750 - acc: 0.7320 - val_loss: 0.7709 - val_acc: 0.6716\n",
            "Epoch 39/1000\n",
            "172/172 - 2s - loss: 0.6739 - acc: 0.7338 - val_loss: 0.7700 - val_acc: 0.6718\n",
            "Epoch 40/1000\n",
            "172/172 - 2s - loss: 0.6735 - acc: 0.7321 - val_loss: 0.7692 - val_acc: 0.6714\n",
            "Epoch 41/1000\n",
            "172/172 - 2s - loss: 0.6701 - acc: 0.7351 - val_loss: 0.7685 - val_acc: 0.6718\n",
            "Epoch 42/1000\n",
            "172/172 - 2s - loss: 0.6663 - acc: 0.7331 - val_loss: 0.7678 - val_acc: 0.6705\n",
            "Epoch 43/1000\n",
            "172/172 - 2s - loss: 0.6667 - acc: 0.7338 - val_loss: 0.7672 - val_acc: 0.6707\n",
            "Epoch 44/1000\n",
            "172/172 - 2s - loss: 0.6637 - acc: 0.7337 - val_loss: 0.7667 - val_acc: 0.6696\n",
            "Epoch 45/1000\n",
            "172/172 - 2s - loss: 0.6589 - acc: 0.7365 - val_loss: 0.7662 - val_acc: 0.6714\n",
            "Epoch 46/1000\n",
            "172/172 - 2s - loss: 0.6587 - acc: 0.7371 - val_loss: 0.7657 - val_acc: 0.6701\n",
            "Epoch 47/1000\n",
            "172/172 - 2s - loss: 0.6589 - acc: 0.7375 - val_loss: 0.7654 - val_acc: 0.6692\n",
            "Epoch 48/1000\n",
            "172/172 - 2s - loss: 0.6568 - acc: 0.7367 - val_loss: 0.7653 - val_acc: 0.6692\n",
            "Epoch 49/1000\n",
            "172/172 - 2s - loss: 0.6540 - acc: 0.7397 - val_loss: 0.7651 - val_acc: 0.6679\n",
            "Epoch 50/1000\n",
            "172/172 - 2s - loss: 0.6506 - acc: 0.7391 - val_loss: 0.7649 - val_acc: 0.6685\n",
            "Epoch 51/1000\n",
            "172/172 - 2s - loss: 0.6505 - acc: 0.7425 - val_loss: 0.7648 - val_acc: 0.6683\n",
            "Epoch 52/1000\n",
            "172/172 - 2s - loss: 0.6477 - acc: 0.7391 - val_loss: 0.7647 - val_acc: 0.6683\n",
            "Epoch 53/1000\n",
            "172/172 - 2s - loss: 0.6497 - acc: 0.7372 - val_loss: 0.7645 - val_acc: 0.6687\n",
            "Epoch 54/1000\n",
            "172/172 - 2s - loss: 0.6481 - acc: 0.7402 - val_loss: 0.7646 - val_acc: 0.6694\n",
            "Epoch 55/1000\n",
            "172/172 - 2s - loss: 0.6403 - acc: 0.7436 - val_loss: 0.7644 - val_acc: 0.6690\n",
            "Epoch 56/1000\n",
            "172/172 - 2s - loss: 0.6402 - acc: 0.7446 - val_loss: 0.7643 - val_acc: 0.6692\n",
            "Epoch 57/1000\n",
            "172/172 - 2s - loss: 0.6364 - acc: 0.7445 - val_loss: 0.7643 - val_acc: 0.6690\n",
            "Epoch 58/1000\n",
            "172/172 - 2s - loss: 0.6409 - acc: 0.7439 - val_loss: 0.7645 - val_acc: 0.6683\n",
            "Epoch 59/1000\n",
            "172/172 - 2s - loss: 0.6369 - acc: 0.7438 - val_loss: 0.7646 - val_acc: 0.6694\n",
            "Validation accuracy: 0.669395923614502, loss: 0.7645625472068787\n",
            "Accuracy: 0.669395923614502, Parameters: (layers=1, units=32)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0745 - acc: 0.4476 - val_loss: 1.0534 - val_acc: 0.4667\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 1.0309 - acc: 0.4932 - val_loss: 1.0210 - val_acc: 0.4942\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.9953 - acc: 0.5340 - val_loss: 0.9938 - val_acc: 0.5444\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.9655 - acc: 0.5795 - val_loss: 0.9704 - val_acc: 0.5713\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.9412 - acc: 0.6084 - val_loss: 0.9502 - val_acc: 0.5904\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.9181 - acc: 0.6253 - val_loss: 0.9324 - val_acc: 0.6026\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.8973 - acc: 0.6405 - val_loss: 0.9166 - val_acc: 0.6181\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.8795 - acc: 0.6518 - val_loss: 0.9028 - val_acc: 0.6234\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.8621 - acc: 0.6639 - val_loss: 0.8903 - val_acc: 0.6328\n",
            "Epoch 10/1000\n",
            "172/172 - 2s - loss: 0.8466 - acc: 0.6727 - val_loss: 0.8789 - val_acc: 0.6350\n",
            "Epoch 11/1000\n",
            "172/172 - 2s - loss: 0.8346 - acc: 0.6746 - val_loss: 0.8689 - val_acc: 0.6447\n",
            "Epoch 12/1000\n",
            "172/172 - 2s - loss: 0.8203 - acc: 0.6834 - val_loss: 0.8596 - val_acc: 0.6490\n",
            "Epoch 13/1000\n",
            "172/172 - 2s - loss: 0.8092 - acc: 0.6853 - val_loss: 0.8512 - val_acc: 0.6497\n",
            "Epoch 14/1000\n",
            "172/172 - 2s - loss: 0.7977 - acc: 0.6911 - val_loss: 0.8435 - val_acc: 0.6505\n",
            "Epoch 15/1000\n",
            "172/172 - 2s - loss: 0.7892 - acc: 0.6945 - val_loss: 0.8366 - val_acc: 0.6557\n",
            "Epoch 16/1000\n",
            "172/172 - 2s - loss: 0.7794 - acc: 0.6974 - val_loss: 0.8303 - val_acc: 0.6576\n",
            "Epoch 17/1000\n",
            "172/172 - 2s - loss: 0.7710 - acc: 0.6989 - val_loss: 0.8245 - val_acc: 0.6588\n",
            "Epoch 18/1000\n",
            "172/172 - 2s - loss: 0.7629 - acc: 0.7060 - val_loss: 0.8192 - val_acc: 0.6594\n",
            "Epoch 19/1000\n",
            "172/172 - 2s - loss: 0.7604 - acc: 0.7021 - val_loss: 0.8144 - val_acc: 0.6599\n",
            "Epoch 20/1000\n",
            "172/172 - 2s - loss: 0.7483 - acc: 0.7100 - val_loss: 0.8100 - val_acc: 0.6598\n",
            "Epoch 21/1000\n",
            "172/172 - 2s - loss: 0.7432 - acc: 0.7094 - val_loss: 0.8060 - val_acc: 0.6623\n",
            "Epoch 22/1000\n",
            "172/172 - 2s - loss: 0.7355 - acc: 0.7141 - val_loss: 0.8022 - val_acc: 0.6628\n",
            "Epoch 23/1000\n",
            "172/172 - 2s - loss: 0.7298 - acc: 0.7172 - val_loss: 0.7989 - val_acc: 0.6638\n",
            "Epoch 24/1000\n",
            "172/172 - 2s - loss: 0.7296 - acc: 0.7132 - val_loss: 0.7958 - val_acc: 0.6656\n",
            "Epoch 25/1000\n",
            "172/172 - 2s - loss: 0.7191 - acc: 0.7189 - val_loss: 0.7929 - val_acc: 0.6667\n",
            "Epoch 26/1000\n",
            "172/172 - 2s - loss: 0.7192 - acc: 0.7163 - val_loss: 0.7903 - val_acc: 0.6681\n",
            "Epoch 27/1000\n",
            "172/172 - 2s - loss: 0.7106 - acc: 0.7223 - val_loss: 0.7878 - val_acc: 0.6674\n",
            "Epoch 28/1000\n",
            "172/172 - 2s - loss: 0.7077 - acc: 0.7228 - val_loss: 0.7857 - val_acc: 0.6685\n",
            "Epoch 29/1000\n",
            "172/172 - 2s - loss: 0.7049 - acc: 0.7213 - val_loss: 0.7837 - val_acc: 0.6687\n",
            "Epoch 30/1000\n",
            "172/172 - 2s - loss: 0.7033 - acc: 0.7227 - val_loss: 0.7817 - val_acc: 0.6681\n",
            "Epoch 31/1000\n",
            "172/172 - 2s - loss: 0.6969 - acc: 0.7246 - val_loss: 0.7801 - val_acc: 0.6692\n",
            "Epoch 32/1000\n",
            "172/172 - 2s - loss: 0.6956 - acc: 0.7245 - val_loss: 0.7784 - val_acc: 0.6692\n",
            "Epoch 33/1000\n",
            "172/172 - 2s - loss: 0.6899 - acc: 0.7283 - val_loss: 0.7770 - val_acc: 0.6714\n",
            "Epoch 34/1000\n",
            "172/172 - 2s - loss: 0.6853 - acc: 0.7281 - val_loss: 0.7756 - val_acc: 0.6707\n",
            "Epoch 35/1000\n",
            "172/172 - 2s - loss: 0.6814 - acc: 0.7303 - val_loss: 0.7743 - val_acc: 0.6710\n",
            "Epoch 36/1000\n",
            "172/172 - 2s - loss: 0.6820 - acc: 0.7284 - val_loss: 0.7732 - val_acc: 0.6736\n",
            "Epoch 37/1000\n",
            "172/172 - 2s - loss: 0.6790 - acc: 0.7336 - val_loss: 0.7721 - val_acc: 0.6727\n",
            "Epoch 38/1000\n",
            "172/172 - 2s - loss: 0.6755 - acc: 0.7320 - val_loss: 0.7710 - val_acc: 0.6723\n",
            "Epoch 39/1000\n",
            "172/172 - 2s - loss: 0.6727 - acc: 0.7340 - val_loss: 0.7702 - val_acc: 0.6723\n",
            "Epoch 40/1000\n",
            "172/172 - 2s - loss: 0.6700 - acc: 0.7313 - val_loss: 0.7696 - val_acc: 0.6723\n",
            "Epoch 41/1000\n",
            "172/172 - 2s - loss: 0.6668 - acc: 0.7344 - val_loss: 0.7687 - val_acc: 0.6730\n",
            "Epoch 42/1000\n",
            "172/172 - 2s - loss: 0.6668 - acc: 0.7343 - val_loss: 0.7680 - val_acc: 0.6723\n",
            "Epoch 43/1000\n",
            "172/172 - 2s - loss: 0.6680 - acc: 0.7327 - val_loss: 0.7677 - val_acc: 0.6738\n",
            "Epoch 44/1000\n",
            "172/172 - 2s - loss: 0.6626 - acc: 0.7360 - val_loss: 0.7671 - val_acc: 0.6723\n",
            "Epoch 45/1000\n",
            "172/172 - 2s - loss: 0.6607 - acc: 0.7398 - val_loss: 0.7666 - val_acc: 0.6721\n",
            "Epoch 46/1000\n",
            "172/172 - 2s - loss: 0.6568 - acc: 0.7365 - val_loss: 0.7662 - val_acc: 0.6729\n",
            "Epoch 47/1000\n",
            "172/172 - 2s - loss: 0.6568 - acc: 0.7381 - val_loss: 0.7659 - val_acc: 0.6736\n",
            "Epoch 48/1000\n",
            "172/172 - 2s - loss: 0.6538 - acc: 0.7423 - val_loss: 0.7655 - val_acc: 0.6729\n",
            "Epoch 49/1000\n",
            "172/172 - 2s - loss: 0.6516 - acc: 0.7415 - val_loss: 0.7651 - val_acc: 0.6727\n",
            "Epoch 50/1000\n",
            "172/172 - 2s - loss: 0.6509 - acc: 0.7399 - val_loss: 0.7650 - val_acc: 0.6730\n",
            "Epoch 51/1000\n",
            "172/172 - 2s - loss: 0.6495 - acc: 0.7419 - val_loss: 0.7648 - val_acc: 0.6727\n",
            "Epoch 52/1000\n",
            "172/172 - 2s - loss: 0.6458 - acc: 0.7413 - val_loss: 0.7647 - val_acc: 0.6721\n",
            "Epoch 53/1000\n",
            "172/172 - 2s - loss: 0.6472 - acc: 0.7416 - val_loss: 0.7645 - val_acc: 0.6719\n",
            "Epoch 54/1000\n",
            "172/172 - 2s - loss: 0.6420 - acc: 0.7458 - val_loss: 0.7645 - val_acc: 0.6723\n",
            "Epoch 55/1000\n",
            "172/172 - 2s - loss: 0.6420 - acc: 0.7445 - val_loss: 0.7645 - val_acc: 0.6718\n",
            "Epoch 56/1000\n",
            "172/172 - 2s - loss: 0.6460 - acc: 0.7404 - val_loss: 0.7644 - val_acc: 0.6727\n",
            "Epoch 57/1000\n",
            "172/172 - 2s - loss: 0.6402 - acc: 0.7399 - val_loss: 0.7645 - val_acc: 0.6729\n",
            "Epoch 58/1000\n",
            "172/172 - 2s - loss: 0.6392 - acc: 0.7438 - val_loss: 0.7646 - val_acc: 0.6719\n",
            "Validation accuracy: 0.6719432473182678, loss: 0.7645593881607056\n",
            "Accuracy: 0.6719432473182678, Parameters: (layers=1, units=64)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0751 - acc: 0.4334 - val_loss: 1.0536 - val_acc: 0.4561\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 1.0314 - acc: 0.4831 - val_loss: 1.0212 - val_acc: 0.4978\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.9970 - acc: 0.5369 - val_loss: 0.9945 - val_acc: 0.5411\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.9678 - acc: 0.5695 - val_loss: 0.9712 - val_acc: 0.5691\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.9423 - acc: 0.6032 - val_loss: 0.9509 - val_acc: 0.5895\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.9187 - acc: 0.6284 - val_loss: 0.9330 - val_acc: 0.6055\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.8973 - acc: 0.6404 - val_loss: 0.9171 - val_acc: 0.6146\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.8783 - acc: 0.6562 - val_loss: 0.9028 - val_acc: 0.6257\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.8617 - acc: 0.6653 - val_loss: 0.8903 - val_acc: 0.6332\n",
            "Epoch 10/1000\n",
            "172/172 - 2s - loss: 0.8477 - acc: 0.6703 - val_loss: 0.8792 - val_acc: 0.6392\n",
            "Epoch 11/1000\n",
            "172/172 - 2s - loss: 0.8338 - acc: 0.6745 - val_loss: 0.8688 - val_acc: 0.6421\n",
            "Epoch 12/1000\n",
            "172/172 - 2s - loss: 0.8216 - acc: 0.6853 - val_loss: 0.8597 - val_acc: 0.6477\n",
            "Epoch 13/1000\n",
            "172/172 - 2s - loss: 0.8094 - acc: 0.6857 - val_loss: 0.8513 - val_acc: 0.6517\n",
            "Epoch 14/1000\n",
            "172/172 - 2s - loss: 0.7991 - acc: 0.6874 - val_loss: 0.8437 - val_acc: 0.6539\n",
            "Epoch 15/1000\n",
            "172/172 - 2s - loss: 0.7898 - acc: 0.6980 - val_loss: 0.8368 - val_acc: 0.6548\n",
            "Epoch 16/1000\n",
            "172/172 - 2s - loss: 0.7792 - acc: 0.6955 - val_loss: 0.8304 - val_acc: 0.6567\n",
            "Epoch 17/1000\n",
            "172/172 - 2s - loss: 0.7722 - acc: 0.7013 - val_loss: 0.8247 - val_acc: 0.6570\n",
            "Epoch 18/1000\n",
            "172/172 - 2s - loss: 0.7638 - acc: 0.7025 - val_loss: 0.8194 - val_acc: 0.6603\n",
            "Epoch 19/1000\n",
            "172/172 - 2s - loss: 0.7582 - acc: 0.7058 - val_loss: 0.8145 - val_acc: 0.6612\n",
            "Epoch 20/1000\n",
            "172/172 - 2s - loss: 0.7523 - acc: 0.7075 - val_loss: 0.8103 - val_acc: 0.6619\n",
            "Epoch 21/1000\n",
            "172/172 - 2s - loss: 0.7448 - acc: 0.7093 - val_loss: 0.8061 - val_acc: 0.6623\n",
            "Epoch 22/1000\n",
            "172/172 - 2s - loss: 0.7375 - acc: 0.7099 - val_loss: 0.8024 - val_acc: 0.6638\n",
            "Epoch 23/1000\n",
            "172/172 - 2s - loss: 0.7323 - acc: 0.7153 - val_loss: 0.7990 - val_acc: 0.6639\n",
            "Epoch 24/1000\n",
            "172/172 - 2s - loss: 0.7290 - acc: 0.7129 - val_loss: 0.7959 - val_acc: 0.6672\n",
            "Epoch 25/1000\n",
            "172/172 - 2s - loss: 0.7230 - acc: 0.7137 - val_loss: 0.7931 - val_acc: 0.6665\n",
            "Epoch 26/1000\n",
            "172/172 - 2s - loss: 0.7199 - acc: 0.7152 - val_loss: 0.7904 - val_acc: 0.6676\n",
            "Epoch 27/1000\n",
            "172/172 - 2s - loss: 0.7096 - acc: 0.7230 - val_loss: 0.7880 - val_acc: 0.6676\n",
            "Epoch 28/1000\n",
            "172/172 - 2s - loss: 0.7087 - acc: 0.7200 - val_loss: 0.7858 - val_acc: 0.6687\n",
            "Epoch 29/1000\n",
            "172/172 - 2s - loss: 0.7077 - acc: 0.7197 - val_loss: 0.7836 - val_acc: 0.6692\n",
            "Epoch 30/1000\n",
            "172/172 - 2s - loss: 0.7020 - acc: 0.7224 - val_loss: 0.7816 - val_acc: 0.6696\n",
            "Epoch 31/1000\n",
            "172/172 - 2s - loss: 0.6994 - acc: 0.7233 - val_loss: 0.7798 - val_acc: 0.6670\n",
            "Epoch 32/1000\n",
            "172/172 - 2s - loss: 0.6923 - acc: 0.7270 - val_loss: 0.7782 - val_acc: 0.6679\n",
            "Epoch 33/1000\n",
            "172/172 - 2s - loss: 0.6909 - acc: 0.7289 - val_loss: 0.7768 - val_acc: 0.6692\n",
            "Epoch 34/1000\n",
            "172/172 - 2s - loss: 0.6856 - acc: 0.7316 - val_loss: 0.7752 - val_acc: 0.6696\n",
            "Epoch 35/1000\n",
            "172/172 - 2s - loss: 0.6834 - acc: 0.7315 - val_loss: 0.7739 - val_acc: 0.6701\n",
            "Epoch 36/1000\n",
            "172/172 - 2s - loss: 0.6835 - acc: 0.7287 - val_loss: 0.7729 - val_acc: 0.6692\n",
            "Epoch 37/1000\n",
            "172/172 - 2s - loss: 0.6796 - acc: 0.7306 - val_loss: 0.7719 - val_acc: 0.6687\n",
            "Epoch 38/1000\n",
            "172/172 - 2s - loss: 0.6779 - acc: 0.7287 - val_loss: 0.7710 - val_acc: 0.6701\n",
            "Epoch 39/1000\n",
            "172/172 - 2s - loss: 0.6748 - acc: 0.7294 - val_loss: 0.7702 - val_acc: 0.6692\n",
            "Epoch 40/1000\n",
            "172/172 - 2s - loss: 0.6704 - acc: 0.7338 - val_loss: 0.7694 - val_acc: 0.6701\n",
            "Epoch 41/1000\n",
            "172/172 - 2s - loss: 0.6709 - acc: 0.7301 - val_loss: 0.7686 - val_acc: 0.6709\n",
            "Epoch 42/1000\n",
            "172/172 - 3s - loss: 0.6661 - acc: 0.7343 - val_loss: 0.7679 - val_acc: 0.6705\n",
            "Epoch 43/1000\n",
            "172/172 - 3s - loss: 0.6676 - acc: 0.7336 - val_loss: 0.7673 - val_acc: 0.6707\n",
            "Epoch 44/1000\n",
            "172/172 - 2s - loss: 0.6616 - acc: 0.7356 - val_loss: 0.7669 - val_acc: 0.6716\n",
            "Epoch 45/1000\n",
            "172/172 - 2s - loss: 0.6593 - acc: 0.7369 - val_loss: 0.7666 - val_acc: 0.6719\n",
            "Epoch 46/1000\n",
            "172/172 - 2s - loss: 0.6547 - acc: 0.7404 - val_loss: 0.7662 - val_acc: 0.6712\n",
            "Epoch 47/1000\n",
            "172/172 - 2s - loss: 0.6570 - acc: 0.7372 - val_loss: 0.7659 - val_acc: 0.6710\n",
            "Epoch 48/1000\n",
            "172/172 - 2s - loss: 0.6528 - acc: 0.7423 - val_loss: 0.7656 - val_acc: 0.6710\n",
            "Epoch 49/1000\n",
            "172/172 - 2s - loss: 0.6520 - acc: 0.7403 - val_loss: 0.7654 - val_acc: 0.6705\n",
            "Epoch 50/1000\n",
            "172/172 - 2s - loss: 0.6531 - acc: 0.7416 - val_loss: 0.7652 - val_acc: 0.6705\n",
            "Epoch 51/1000\n",
            "172/172 - 2s - loss: 0.6488 - acc: 0.7424 - val_loss: 0.7648 - val_acc: 0.6696\n",
            "Epoch 52/1000\n",
            "172/172 - 2s - loss: 0.6490 - acc: 0.7390 - val_loss: 0.7646 - val_acc: 0.6709\n",
            "Epoch 53/1000\n",
            "172/172 - 2s - loss: 0.6408 - acc: 0.7443 - val_loss: 0.7643 - val_acc: 0.6699\n",
            "Epoch 54/1000\n",
            "172/172 - 2s - loss: 0.6456 - acc: 0.7433 - val_loss: 0.7644 - val_acc: 0.6705\n",
            "Epoch 55/1000\n",
            "172/172 - 2s - loss: 0.6444 - acc: 0.7398 - val_loss: 0.7644 - val_acc: 0.6703\n",
            "Validation accuracy: 0.6703056693077087, loss: 0.7643939256668091\n",
            "Accuracy: 0.6703056693077087, Parameters: (layers=1, units=128)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0582 - acc: 0.4627 - val_loss: 1.0024 - val_acc: 0.5360\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 0.9458 - acc: 0.5906 - val_loss: 0.8964 - val_acc: 0.6399\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.8556 - acc: 0.6449 - val_loss: 0.8288 - val_acc: 0.6667\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.7981 - acc: 0.6610 - val_loss: 0.7896 - val_acc: 0.6745\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.7621 - acc: 0.6790 - val_loss: 0.7676 - val_acc: 0.6818\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.7356 - acc: 0.6865 - val_loss: 0.7533 - val_acc: 0.6861\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.7239 - acc: 0.6945 - val_loss: 0.7459 - val_acc: 0.6849\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.7067 - acc: 0.7030 - val_loss: 0.7408 - val_acc: 0.6881\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.6902 - acc: 0.7098 - val_loss: 0.7368 - val_acc: 0.6883\n",
            "Epoch 10/1000\n",
            "172/172 - 2s - loss: 0.6840 - acc: 0.7129 - val_loss: 0.7374 - val_acc: 0.6881\n",
            "Epoch 11/1000\n",
            "172/172 - 2s - loss: 0.6754 - acc: 0.7181 - val_loss: 0.7378 - val_acc: 0.6885\n",
            "Validation accuracy: 0.688500702381134, loss: 0.7377502918243408\n",
            "Accuracy: 0.688500702381134, Parameters: (layers=2, units=8)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0377 - acc: 0.4677 - val_loss: 0.9555 - val_acc: 0.5660\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 0.8900 - acc: 0.6276 - val_loss: 0.8383 - val_acc: 0.6634\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.7948 - acc: 0.6786 - val_loss: 0.7826 - val_acc: 0.6852\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.7433 - acc: 0.6957 - val_loss: 0.7591 - val_acc: 0.6854\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.7156 - acc: 0.7078 - val_loss: 0.7495 - val_acc: 0.6827\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.6914 - acc: 0.7160 - val_loss: 0.7445 - val_acc: 0.6860\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.6770 - acc: 0.7228 - val_loss: 0.7443 - val_acc: 0.6832\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.6643 - acc: 0.7297 - val_loss: 0.7462 - val_acc: 0.6799\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.6498 - acc: 0.7380 - val_loss: 0.7512 - val_acc: 0.6796\n",
            "Validation accuracy: 0.6795851588249207, loss: 0.7512491345405579\n",
            "Accuracy: 0.6795851588249207, Parameters: (layers=2, units=16)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0226 - acc: 0.4950 - val_loss: 0.9186 - val_acc: 0.6061\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 0.8380 - acc: 0.6509 - val_loss: 0.7929 - val_acc: 0.6654\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.7425 - acc: 0.6930 - val_loss: 0.7555 - val_acc: 0.6741\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.6963 - acc: 0.7096 - val_loss: 0.7457 - val_acc: 0.6772\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.6741 - acc: 0.7230 - val_loss: 0.7427 - val_acc: 0.6845\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.6508 - acc: 0.7316 - val_loss: 0.7465 - val_acc: 0.6847\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.6344 - acc: 0.7391 - val_loss: 0.7505 - val_acc: 0.6807\n",
            "Validation accuracy: 0.6806768774986267, loss: 0.7504748702049255\n",
            "Accuracy: 0.6806768774986267, Parameters: (layers=2, units=32)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 0.9945 - acc: 0.5163 - val_loss: 0.8568 - val_acc: 0.6376\n",
            "Epoch 2/1000\n",
            "172/172 - 3s - loss: 0.7820 - acc: 0.6744 - val_loss: 0.7591 - val_acc: 0.6818\n",
            "Epoch 3/1000\n",
            "172/172 - 3s - loss: 0.7041 - acc: 0.7090 - val_loss: 0.7433 - val_acc: 0.6850\n",
            "Epoch 4/1000\n",
            "172/172 - 3s - loss: 0.6684 - acc: 0.7216 - val_loss: 0.7465 - val_acc: 0.6758\n",
            "Epoch 5/1000\n",
            "172/172 - 3s - loss: 0.6486 - acc: 0.7291 - val_loss: 0.7512 - val_acc: 0.6758\n",
            "Validation accuracy: 0.6757642030715942, loss: 0.7512468099594116\n",
            "Accuracy: 0.6757642030715942, Parameters: (layers=2, units=64)\n",
            "Epoch 1/1000\n",
            "172/172 - 4s - loss: 0.9580 - acc: 0.5424 - val_loss: 0.8005 - val_acc: 0.6692\n",
            "Epoch 2/1000\n",
            "172/172 - 3s - loss: 0.7409 - acc: 0.6886 - val_loss: 0.7471 - val_acc: 0.6845\n",
            "Epoch 3/1000\n",
            "172/172 - 3s - loss: 0.6871 - acc: 0.7117 - val_loss: 0.7448 - val_acc: 0.6809\n",
            "Epoch 4/1000\n",
            "172/172 - 3s - loss: 0.6487 - acc: 0.7296 - val_loss: 0.7515 - val_acc: 0.6754\n",
            "Epoch 5/1000\n",
            "172/172 - 3s - loss: 0.6328 - acc: 0.7354 - val_loss: 0.7590 - val_acc: 0.6747\n",
            "Validation accuracy: 0.6746724843978882, loss: 0.7589600682258606\n",
            "Accuracy: 0.6746724843978882, Parameters: (layers=2, units=128)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0632 - acc: 0.4638 - val_loss: 0.9932 - val_acc: 0.5340\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 0.9423 - acc: 0.5399 - val_loss: 0.8722 - val_acc: 0.5715\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.8604 - acc: 0.5821 - val_loss: 0.8143 - val_acc: 0.6301\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.8151 - acc: 0.6339 - val_loss: 0.7817 - val_acc: 0.6850\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.7827 - acc: 0.6512 - val_loss: 0.7630 - val_acc: 0.6894\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.7571 - acc: 0.6715 - val_loss: 0.7556 - val_acc: 0.6880\n",
            "Epoch 7/1000\n",
            "172/172 - 2s - loss: 0.7405 - acc: 0.6803 - val_loss: 0.7519 - val_acc: 0.6858\n",
            "Epoch 8/1000\n",
            "172/172 - 2s - loss: 0.7271 - acc: 0.6899 - val_loss: 0.7516 - val_acc: 0.6841\n",
            "Epoch 9/1000\n",
            "172/172 - 2s - loss: 0.7032 - acc: 0.6992 - val_loss: 0.7498 - val_acc: 0.6816\n",
            "Epoch 10/1000\n",
            "172/172 - 2s - loss: 0.7002 - acc: 0.7015 - val_loss: 0.7517 - val_acc: 0.6847\n",
            "Epoch 11/1000\n",
            "172/172 - 2s - loss: 0.6928 - acc: 0.7050 - val_loss: 0.7543 - val_acc: 0.6794\n",
            "Validation accuracy: 0.6794031858444214, loss: 0.7542950510978699\n",
            "Accuracy: 0.6794031858444214, Parameters: (layers=3, units=8)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0501 - acc: 0.4475 - val_loss: 0.9362 - val_acc: 0.6206\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 0.8499 - acc: 0.6333 - val_loss: 0.7624 - val_acc: 0.6809\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.7539 - acc: 0.6875 - val_loss: 0.7403 - val_acc: 0.6860\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.7071 - acc: 0.7104 - val_loss: 0.7356 - val_acc: 0.6854\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.6888 - acc: 0.7176 - val_loss: 0.7393 - val_acc: 0.6823\n",
            "Epoch 6/1000\n",
            "172/172 - 2s - loss: 0.6671 - acc: 0.7278 - val_loss: 0.7455 - val_acc: 0.6739\n",
            "Validation accuracy: 0.6739447116851807, loss: 0.7454718351364136\n",
            "Accuracy: 0.6739447116851807, Parameters: (layers=3, units=16)\n",
            "Epoch 1/1000\n",
            "172/172 - 3s - loss: 1.0063 - acc: 0.4989 - val_loss: 0.8232 - val_acc: 0.6583\n",
            "Epoch 2/1000\n",
            "172/172 - 2s - loss: 0.7818 - acc: 0.6668 - val_loss: 0.7482 - val_acc: 0.6790\n",
            "Epoch 3/1000\n",
            "172/172 - 2s - loss: 0.7085 - acc: 0.7047 - val_loss: 0.7454 - val_acc: 0.6836\n",
            "Epoch 4/1000\n",
            "172/172 - 2s - loss: 0.6731 - acc: 0.7244 - val_loss: 0.7514 - val_acc: 0.6796\n",
            "Epoch 5/1000\n",
            "172/172 - 2s - loss: 0.6489 - acc: 0.7367 - val_loss: 0.7607 - val_acc: 0.6741\n",
            "Validation accuracy: 0.6741266250610352, loss: 0.7607356905937195\n",
            "Accuracy: 0.6741266250610352, Parameters: (layers=3, units=32)\n",
            "Epoch 1/1000\n",
            "172/172 - 4s - loss: 0.9542 - acc: 0.5269 - val_loss: 0.7601 - val_acc: 0.6825\n",
            "Epoch 2/1000\n",
            "172/172 - 3s - loss: 0.7365 - acc: 0.6904 - val_loss: 0.7424 - val_acc: 0.6825\n",
            "Epoch 3/1000\n",
            "172/172 - 3s - loss: 0.6825 - acc: 0.7193 - val_loss: 0.7503 - val_acc: 0.6801\n",
            "Epoch 4/1000\n",
            "172/172 - 3s - loss: 0.6497 - acc: 0.7355 - val_loss: 0.7549 - val_acc: 0.6741\n",
            "Validation accuracy: 0.6741266250610352, loss: 0.754949688911438\n",
            "Accuracy: 0.6741266250610352, Parameters: (layers=3, units=64)\n",
            "Epoch 1/1000\n",
            "172/172 - 4s - loss: 0.9175 - acc: 0.5581 - val_loss: 0.7459 - val_acc: 0.6843\n",
            "Epoch 2/1000\n",
            "172/172 - 3s - loss: 0.7171 - acc: 0.6987 - val_loss: 0.7444 - val_acc: 0.6818\n",
            "Epoch 3/1000\n",
            "172/172 - 3s - loss: 0.6575 - acc: 0.7298 - val_loss: 0.7487 - val_acc: 0.6759\n",
            "Epoch 4/1000\n",
            "172/172 - 3s - loss: 0.6136 - acc: 0.7503 - val_loss: 0.7628 - val_acc: 0.6745\n",
            "Validation accuracy: 0.6744905114173889, loss: 0.7627701163291931\n",
            "Accuracy: 0.6744905114173889, Parameters: (layers=3, units=128)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot(model, to_file='tfNN_model.png')"
      ],
      "metadata": {
        "id": "QSMRDfgeE9MZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}